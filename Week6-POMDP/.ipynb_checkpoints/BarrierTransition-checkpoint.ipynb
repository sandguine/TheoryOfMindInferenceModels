{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.701687Z",
     "start_time": "2019-02-15T19:49:17.654919Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.813164Z",
     "start_time": "2019-02-15T19:49:17.702844Z"
    }
   },
   "outputs": [],
   "source": [
    "from setupPOMDP import *\n",
    "from visualizeEnvironment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T22:07:43.177685Z",
     "start_time": "2019-02-15T22:07:43.173452Z"
    }
   },
   "outputs": [],
   "source": [
    "class SetupEpsilonTransitionWithBarrier(object):\n",
    "    def __init__(self, stateSet, actionSet):\n",
    "        self.stateSet = stateSet\n",
    "        self.actionSet = actionSet\n",
    "\n",
    "    def __call__(self, barrierList, epsilon=0):\n",
    "        transitionTable = {state: {action:  self.getStateActionTransition(state, action, epsilon, barrierList) \\\n",
    "                                   for action in self.actionSet}\\\n",
    "                           for state in self.stateSet}\n",
    "        return(transitionTable) \n",
    "\n",
    "    \n",
    "    def getStateActionTransition(self, currentState, action, epsilon, barriers):\n",
    "        \n",
    "        nextState = self.getNextState(currentState, action, barriers)\n",
    "        \n",
    "        if currentState == nextState or epsilon == 0:\n",
    "            transitionDistribution = {nextState: 1}\n",
    "        else:\n",
    "            transitionDistribution = {nextState: 1-epsilon, currentState:epsilon}\n",
    "            \n",
    "        return(transitionDistribution)\n",
    "\n",
    "    \n",
    "    def getNextState(self, state, action, barriers):\n",
    "        potentialNextState = tuple([state[i] + action[i] for i in range(len(state))])\n",
    "        \n",
    "        if potentialNextState in self.stateSet and (not [state, potentialNextState] in barriers):\n",
    "            return(potentialNextState)\n",
    "        return(state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T22:05:22.546749Z",
     "start_time": "2019-02-15T22:05:22.540280Z"
    }
   },
   "outputs": [],
   "source": [
    "a = [[(1,0), (1,1)], [(2,0), (2,1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T22:05:49.007976Z",
     "start_time": "2019-02-15T22:05:49.002907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(1,0), (1,1)] in a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.816861Z",
     "start_time": "2019-02-15T19:49:17.814257Z"
    }
   },
   "outputs": [],
   "source": [
    "# Actions correspond to E, N, W, S, Stay respectively\n",
    "allActions = [(1,0), (0,1), (-1,0), (0,-1), (0,0)]\n",
    "\n",
    "#all location states in grid\n",
    "gridWidth = 5\n",
    "gridHeight = 5\n",
    "gridSet = set(itertools.product(range(gridWidth), range(gridHeight)))\n",
    "\n",
    "#set of states to remove from each environment\n",
    "barriersC = {(2,1), (3,1), (4,1)}\n",
    "\n",
    "#final environment state sets\n",
    "stateSetC = list(gridSet.difference(barriersC))\n",
    "\n",
    "#goal locations\n",
    "goal1 = (0,4)\n",
    "goal2 = (4,4)\n",
    "\n",
    "#probability of ineffective action\n",
    "epsilon = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.821922Z",
     "start_time": "2019-02-15T19:49:17.818120Z"
    }
   },
   "outputs": [],
   "source": [
    "getTransition = SetupEpsilonTransition(epsilon)\n",
    "\n",
    "# possible environment transitions\n",
    "environmentC = getTransition(stateSetC, allActions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.825534Z",
     "start_time": "2019-02-15T19:49:17.823060Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Probabilistically draw the next location state given the dynamics of the transition function\n",
    "Input: transition dictionary, current state tuple, action tuple\n",
    "Output: next location state tuple\n",
    "\"\"\"\n",
    "def drawNextState(transitionFunction, state, action):\n",
    "    nextStates = list(transitionFunction[state][action].keys())\n",
    "    probabilities = list(transitionFunction[state][action].values())\n",
    "    nextState = nextStates[np.random.choice(len(nextStates), p=probabilities)]\n",
    "    return(nextState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.830707Z",
     "start_time": "2019-02-15T19:49:17.826675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example:\n",
    "drawNextState(environmentC, (0,0), (1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment C Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.841369Z",
     "start_time": "2019-02-15T19:49:17.831781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: (3, 2)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\tprobability: 1\n",
      "state: (1, 3)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\tprobability: 1\n",
      "state: (0, 0)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\tprobability: 1\n",
      "state: (3, 0)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 0)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\tprobability: 1\n",
      "state: (1, 4)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\tprobability: 1\n",
      "state: (1, 1)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\tprobability: 1\n",
      "state: (2, 3)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\tprobability: 1\n",
      "state: (4, 2)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\tprobability: 1\n",
      "state: (0, 3)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\tprobability: 1\n",
      "state: (1, 0)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\tprobability: 1\n",
      "state: (2, 4)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\tprobability: 1\n",
      "state: (4, 0)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 0)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (4, 0)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (4, 0)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (4, 0)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (4, 0)\n",
      "\t\t\tprobability: 1\n",
      "state: (1, 2)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\tprobability: 1\n",
      "state: (0, 1)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\tprobability: 1\n",
      "state: (3, 3)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\tprobability: 1\n",
      "state: (4, 4)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\tprobability: 1\n",
      "state: (2, 0)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\tprobability: 1\n",
      "state: (0, 4)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\tprobability: 1\n",
      "state: (4, 3)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\tprobability: 1\n",
      "state: (2, 2)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\tprobability: 1\n",
      "state: (3, 4)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\tprobability: 1\n",
      "state: (0, 2)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\tprobability: 1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\tprobability: 0.9\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\tprobability: 0.1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\tprobability: 1\n"
     ]
    }
   ],
   "source": [
    "viewDictionaryStructure(environmentC, [\"state\", \"action\", \"next state\", \"probability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.964683Z",
     "start_time": "2019-02-15T19:49:17.842823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizeEnvironment(gridWidth = gridWidth, gridHeight = gridHeight, states = stateSetC, \\\n",
    "                     goalStates = [(0,4, \" \"), (4,4, \" \")], trajectory = [(3,2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lists all possible worlds as well as all possible preference rankings among K, L, and M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.969802Z",
     "start_time": "2019-02-15T19:49:17.966606Z"
    }
   },
   "outputs": [],
   "source": [
    "allWorlds = [(c1, c2) for c1, c2 in itertools.permutations(\"KLM\", 2)]\n",
    "possibleWorldsInLocation = [{goal1: comb1, goal2: comb2} for comb1, comb2 in itertools.permutations(\"KLM\", 2)]\n",
    "possiblePreferenceRankings = [rank for rank in itertools.permutations(\"KLM\",3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.975368Z",
     "start_time": "2019-02-15T19:49:17.971487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('K', 'L'), ('K', 'M'), ('L', 'K'), ('L', 'M'), ('M', 'K'), ('M', 'L')] \n",
      "\n",
      "[{(0, 4): 'K', (4, 4): 'L'}, {(0, 4): 'K', (4, 4): 'M'}, {(0, 4): 'L', (4, 4): 'K'}, {(0, 4): 'L', (4, 4): 'M'}, {(0, 4): 'M', (4, 4): 'K'}, {(0, 4): 'M', (4, 4): 'L'}] \n",
      "\n",
      "[('K', 'L', 'M'), ('K', 'M', 'L'), ('L', 'K', 'M'), ('L', 'M', 'K'), ('M', 'K', 'L'), ('M', 'L', 'K')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(allWorlds, \"\\n\")\n",
    "print(possibleWorldsInLocation, \"\\n\")\n",
    "print(possiblePreferenceRankings, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.980320Z",
     "start_time": "2019-02-15T19:49:17.977002Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Construct the input for a reward function.\n",
    "\n",
    "Inputs: world is a dictionary where keys are the coordinates of goals and the values are the names of those goals\n",
    "preference is a tuple indicating the relatve ranking of the worth of goals and \n",
    "preference rewards is a list of how much reward the rank of each goal should receive\n",
    "\n",
    "outputs: a dictionary with goal locations as keys and the numerical reward associated with them as the values\n",
    "\"\"\"\n",
    "def constructPreferences(world, preference, preferenceRewards = [1000, 400, 100]):\n",
    "    goalPreferences = {location : preferenceRewards[preference.index(truck)] for location, truck in world.items()}\n",
    "    return(goalPreferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.985544Z",
     "start_time": "2019-02-15T19:49:17.982127Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): 400, (9, 4): 100}\n",
      "{(0, 4): 400, (4, 4): 100}\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "print(constructPreferences({(0,0):'L', (9,4):'K'}, ('M', 'L', 'K')))\n",
    "print(constructPreferences(possibleWorldsInLocation[2], possiblePreferenceRankings[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewards R(s, a, s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reward is defined for first, the environment, and second for the relative preferences of the agent. \n",
    "We create a reward for each possible world, given that preference relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:17.990255Z",
     "start_time": "2019-02-15T19:49:17.987188Z"
    }
   },
   "outputs": [],
   "source": [
    "getRewardC = SetupRewardTable(environmentC, allActions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:18.012722Z",
     "start_time": "2019-02-15T19:49:17.991725Z"
    }
   },
   "outputs": [],
   "source": [
    "# example preference of M > K > L, a true world of K in position 0,0 and L in position 9,4\n",
    "klWorld_mlkPreference = constructPreferences(possibleWorldsInLocation[2], possiblePreferenceRankings[-1])\n",
    "\n",
    "# example reward function dictionaries for environment C dynamics, Preference M > K > L \n",
    "rewards_EnvC_PrefMLK = {tuple(world.values()) : getRewardC(constructPreferences(world, possiblePreferenceRankings[-1])) \\\n",
    "                        for world in possibleWorldsInLocation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:18.024177Z",
     "start_time": "2019-02-15T19:49:18.013979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: (3, 2)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\treward: -1\n",
      "state: (1, 3)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\treward: -1\n",
      "state: (0, 0)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\treward: -1\n",
      "state: (3, 0)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 0)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\treward: -1\n",
      "state: (1, 4)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\treward: -1\n",
      "state: (1, 1)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\treward: -1\n",
      "state: (2, 3)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\treward: -1\n",
      "state: (4, 2)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\treward: -1\n",
      "state: (0, 3)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\treward: -1\n",
      "state: (1, 0)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\treward: -1\n",
      "state: (2, 4)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\treward: -1\n",
      "state: (4, 0)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (4, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (4, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (4, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (4, 0)\n",
      "\t\t\treward: -1\n",
      "state: (1, 2)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (1, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\treward: -1\n",
      "state: (0, 1)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (1, 1)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (0, 0)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\treward: -1\n",
      "state: (3, 3)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\treward: -1\n",
      "state: (4, 4)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\treward: 100\n",
      "state: (2, 0)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (3, 0)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (1, 0)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (2, 0)\n",
      "\t\t\treward: -1\n",
      "state: (0, 4)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (1, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (0, 4)\n",
      "\t\t\treward: 400\n",
      "state: (4, 3)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (4, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (4, 3)\n",
      "\t\t\treward: -1\n",
      "state: (2, 2)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (3, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (2, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (2, 2)\n",
      "\t\t\treward: -1\n",
      "state: (3, 4)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (4, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (2, 4)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (3, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (3, 4)\n",
      "\t\t\treward: -1\n",
      "state: (0, 2)\n",
      "\taction: (1, 0)\n",
      "\t\tnext state: (1, 2)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 1)\n",
      "\t\tnext state: (0, 3)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (-1, 0)\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, -1)\n",
      "\t\tnext state: (0, 1)\n",
      "\t\t\treward: -1\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\treward: -1\n",
      "\taction: (0, 0)\n",
      "\t\tnext state: (0, 2)\n",
      "\t\t\treward: -1\n"
     ]
    }
   ],
   "source": [
    "viewDictionaryStructure(rewards_EnvC_PrefMLK[('L', 'K')], levelsReward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Belief Rewards Rho(b, s, a, s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:18.029244Z",
     "start_time": "2019-02-15T19:49:18.026756Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBeliefReward(worldBeliefs, worldRewardFunctions, state, action, nextState):\n",
    "    beliefReward = sum([worldBeliefs[y]*worldRewardFunctions[y][state][action][nextState] for y in worldBeliefs])\n",
    "    return(beliefReward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:18.035144Z",
     "start_time": "2019-02-15T19:49:18.031414Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "impartial_b = {world: 1/6 for world in itertools.permutations(\"KLM\", 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:18.039412Z",
     "start_time": "2019-02-15T19:49:18.036566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9999999999999999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getBeliefReward(impartial_b, rewards_EnvC_PrefMLK, (0,0), (0,0), (0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Belief Updating: Tau(b, a, b') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ b_t(y) \\propto p(o_t|x_t, y, env)b_{t-1}(y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T00:56:22.869012Z",
     "start_time": "2019-02-12T00:56:22.863926Z"
    }
   },
   "source": [
    "## constructing P(o|x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T19:49:18.044484Z",
     "start_time": "2019-02-15T19:49:18.040746Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-19-000b95b2d561>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-000b95b2d561>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def createObservations(environment, trueWorldInLocation, stateSet):\n",
    "    #{world : position state : possible goal: indicator of whether that possible goal is visible in that state/world combo}\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
