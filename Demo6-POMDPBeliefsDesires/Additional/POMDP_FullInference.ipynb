{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T21:25:23.393397Z",
     "start_time": "2019-11-22T21:25:23.066017Z"
    }
   },
   "outputs": [],
   "source": [
    "from beliefPOMDPFunctions import *\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from SetupTransitionTable import SetupDeterministicTransitionByStateSet\n",
    "from SetupRewardTable import SetupStateActionRewardWithUserSpecifiedCosts\n",
    "from visualizations import *\n",
    "from ValueIteration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:12:12.188030Z",
     "start_time": "2019-03-05T00:12:12.183209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Actions correspond to E, N, W, S, Stay respectively\n",
    "allActions = [(1,0), (0,1), (-1,0), (0,-1), (0,0)]\n",
    "\n",
    "#all location states in grid\n",
    "gridWidth = 5\n",
    "gridHeight = 4\n",
    "gridSet = set(itertools.product(range(gridWidth), range(gridHeight)))\n",
    "barriersC = {(2,2), (3,2), (4,2)}\n",
    "\n",
    "#final environment state sets\n",
    "stateSetC = list(gridSet.difference(barriersC))\n",
    "\n",
    "#goal locations\n",
    "goalTruck1 = (0,0)\n",
    "goalTruck2 = (4,3)\n",
    "\n",
    "#possible beliefs\n",
    "beliefSet= list(set([t for t in itertools.permutations([1,0,0,0,0,0], 6)]))\n",
    "otherHypotheses = [(.5,.5,0,0,0,0),(0,0,.5,.5,0,0),(0,0,0,0,.5,.5),(0,0,.5,0,0.5,0),(.5,0,0,0,0,0.5),(0,.5,0,.5,0,0),(.17,.17,.17,.17,.17,.17)]\n",
    "beliefSet.extend(otherHypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:12:12.416570Z",
     "start_time": "2019-03-05T00:12:12.189505Z"
    }
   },
   "outputs": [],
   "source": [
    "getTransition = SetupDeterministicTransitionByStateSet(stateSetC, allActions)\n",
    "positionTransition = getTransition()\n",
    "\n",
    "getTransitionC = SetupBeliefTransition(stateSetC, beliefSet, allActions)\n",
    "beliefTransition_EnvC = getTransitionC(updateBelief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:12:12.423048Z",
     "start_time": "2019-03-05T00:12:12.418010Z"
    }
   },
   "outputs": [],
   "source": [
    "allWorlds = ['KL', 'KM', 'LK', 'LM', 'MK', 'ML']\n",
    "allPreferences = [''.join(preference) for preference in itertools.permutations(\"KLM\",3)]\n",
    "allPreferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:12:12.470925Z",
     "start_time": "2019-03-05T00:12:12.424752Z"
    }
   },
   "outputs": [],
   "source": [
    "getRewardC = SetupStateActionRewardWithUserSpecifiedCosts(positionTransition, allActions, [goalTruck1,goalTruck2])\n",
    "\n",
    "rewards_EnvC_PrefKLM = [getRewardC(constructGoalStateRewards(world, 'KLM')) for world in allWorlds]\n",
    "rewards_EnvC_PrefKML = [getRewardC(constructGoalStateRewards(world, 'KML')) for world in allWorlds]\n",
    "rewards_EnvC_PrefLKM = [getRewardC(constructGoalStateRewards(world, 'LKM')) for world in allWorlds]\n",
    "rewards_EnvC_PrefLMK = [getRewardC(constructGoalStateRewards(world, 'LMK')) for world in allWorlds]\n",
    "rewards_EnvC_PrefMKL = [getRewardC(constructGoalStateRewards(world, 'MKL')) for world in allWorlds]\n",
    "rewards_EnvC_PrefMLK = [getRewardC(constructGoalStateRewards(world, 'MLK')) for world in allWorlds]\n",
    "\n",
    "getRewardBeliefs = SetupRewardBeliefTable(stateSetC, beliefSet, allActions)\n",
    "\n",
    "beliefReward_EnvC_KLM = getRewardBeliefs(beliefTransition_EnvC, rewards_EnvC_PrefKLM)\n",
    "beliefReward_EnvC_KML = getRewardBeliefs(beliefTransition_EnvC, rewards_EnvC_PrefKML)\n",
    "beliefReward_EnvC_LKM = getRewardBeliefs(beliefTransition_EnvC, rewards_EnvC_PrefLKM)\n",
    "beliefReward_EnvC_LMK = getRewardBeliefs(beliefTransition_EnvC, rewards_EnvC_PrefLMK)\n",
    "beliefReward_EnvC_MKL = getRewardBeliefs(beliefTransition_EnvC, rewards_EnvC_PrefMKL)\n",
    "beliefReward_EnvC_MLK = getRewardBeliefs(beliefTransition_EnvC, rewards_EnvC_PrefMLK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Preference Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:12:33.177845Z",
     "start_time": "2019-03-05T00:12:12.472874Z"
    }
   },
   "outputs": [],
   "source": [
    "valueTable = {state:0 for state in beliefTransition_EnvC.keys()}\n",
    "\n",
    "getPolicy_EnvC_KLM = BoltzmannValueIteration(beliefTransition_EnvC, beliefReward_EnvC_KLM, valueTable, 10e-7, .99, .8)\n",
    "optimalValues_KLM, policy_EnvC_KLM = getPolicy_EnvC_KLM()\n",
    "\n",
    "getPolicy_EnvC_KML = BoltzmannValueIteration(beliefTransition_EnvC, beliefReward_EnvC_KML, valueTable, 10e-7, .99, .8)\n",
    "optimalValues_KML, policy_EnvC_KML = getPolicy_EnvC_KML()\n",
    "\n",
    "getPolicy_EnvC_LKM = BoltzmannValueIteration(beliefTransition_EnvC, beliefReward_EnvC_LKM, valueTable, 10e-7, .99, .8)\n",
    "optimalValues_LKM, policy_EnvC_LKM = getPolicy_EnvC_LKM()\n",
    "\n",
    "getPolicy_EnvC_LMK = BoltzmannValueIteration(beliefTransition_EnvC, beliefReward_EnvC_LMK, valueTable, 10e-7, .99, .8)\n",
    "optimalValues_LMK, policy_EnvC_LMK = getPolicy_EnvC_LMK()\n",
    "\n",
    "getPolicy_EnvC_MKL = BoltzmannValueIteration(beliefTransition_EnvC, beliefReward_EnvC_MKL, valueTable, 10e-7, .99, .8)\n",
    "optimalValues_MKL, policy_EnvC_MKL = getPolicy_EnvC_MKL()\n",
    "\n",
    "getPolicy_EnvC_MLK = BoltzmannValueIteration(beliefTransition_EnvC, beliefReward_EnvC_MLK, valueTable, 10e-7, .99, .8)\n",
    "optimalValues_MLK, policy_EnvC_MLK = getPolicy_EnvC_MLK()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:12:42.003286Z",
     "start_time": "2019-03-05T00:12:33.180003Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"KLM \\n\")\n",
    "[print(allWorlds,\"\\n\",list(b), visualizePolicyOfBeliefByState(stateSetC, policy_EnvC_KLM, b, goalStates = [goalTruck1, goalTruck2])) for b in beliefSet]\n",
    "print(\"KML \\n\")\n",
    "[print(allWorlds,\"\\n\",list(b), visualizePolicyOfBeliefByState(stateSetC, policy_EnvC_KML, b, goalStates = [goalTruck1, goalTruck2])) for b in beliefSet]\n",
    "print(\"LKM \\n\")\n",
    "[print(allWorlds,\"\\n\",list(b), visualizePolicyOfBeliefByState(stateSetC, policy_EnvC_LKM, b, goalStates = [goalTruck1, goalTruck2])) for b in beliefSet]\n",
    "print(\"LMK \\n\")\n",
    "[print(allWorlds,\"\\n\",list(b), visualizePolicyOfBeliefByState(stateSetC, policy_EnvC_LMK, b, goalStates = [goalTruck1, goalTruck2])) for b in beliefSet]\n",
    "print(\"MKL \\n\")\n",
    "[print(allWorlds,\"\\n\",list(b), visualizePolicyOfBeliefByState(stateSetC, policy_EnvC_MKL, b, goalStates = [goalTruck1, goalTruck2])) for b in beliefSet]\n",
    "print(\"MLK \\n\")\n",
    "[print(allWorlds,\"\\n\",list(b), visualizePolicyOfBeliefByState(stateSetC, policy_EnvC_MLK, b, goalStates = [goalTruck1, goalTruck2])) for b in beliefSet]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T19:37:22.870852Z",
     "start_time": "2019-03-04T19:37:22.857148Z"
    }
   },
   "source": [
    "# Example Sampled Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:12:42.009434Z",
     "start_time": "2019-03-05T00:12:42.005103Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(130)\n",
    "path1 = samplePathToGoal((4,1), (.17,.17,.17,.17,.17,.17), policy_EnvC_MLK, beliefTransition_EnvC, [(0,0), (4,3)])\n",
    "positionTrajectory1 = [pos for pos, belief in path1]\n",
    "\n",
    "world1 = convertBeliefToTruck(path1[-1][1])\n",
    "worldNames1 = {(0,0): world1[0], (4,3):world1[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:12:42.101264Z",
     "start_time": "2019-03-05T00:12:42.011019Z"
    }
   },
   "outputs": [],
   "source": [
    "visualizeEnvironmentByState(states = stateSetC, goalStates = [(0,0), (4,3)], trajectory = positionTrajectory1, goalNameDictionary=worldNames1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:12:42.108224Z",
     "start_time": "2019-03-05T00:12:42.103176Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "path2 = samplePathToGoal((4,1), (.17,.17,.17,.17,.17,.17), policy_EnvC_LKM, beliefTransition_EnvC, [(0,0), (4,3)])\n",
    "positionTrajectory2 = [pos for pos, belief in path2]\n",
    "\n",
    "world2 = convertBeliefToTruck(path2[-1][1])\n",
    "worldNames2 = {(0,0): world2[0], (4,3):world2[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:12:42.195417Z",
     "start_time": "2019-03-05T00:12:42.110632Z"
    }
   },
   "outputs": [],
   "source": [
    "visualizeEnvironmentByState(states = stateSetC, goalStates = [(0,0), (4,3)], trajectory = positionTrajectory2, goalNameDictionary=worldNames2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:12:42.203341Z",
     "start_time": "2019-03-05T00:12:42.197956Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "path3 = samplePathToGoal((4,1), (.17,.17,.17,.17,.17,.17), policy_EnvC_KML, beliefTransition_EnvC, [(0,0), (4,3)])\n",
    "positionTrajectory3 = [pos for pos, belief in path3]\n",
    "\n",
    "world3 = convertBeliefToTruck(path3[-1][1])\n",
    "worldNames3 = {(0,0): world3[0], (4,3):world3[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:12:42.302135Z",
     "start_time": "2019-03-05T00:12:42.205699Z"
    }
   },
   "outputs": [],
   "source": [
    "visualizeEnvironmentByState(states = stateSetC, goalStates = [(0,0), (4,3)], trajectory = positionTrajectory3, goalNameDictionary=worldNames3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T00:59:23.110613Z",
     "start_time": "2019-03-05T00:59:23.089855Z"
    }
   },
   "outputs": [],
   "source": [
    "preferencePolicies = [policy_EnvC_KLM, policy_EnvC_KML, policy_EnvC_LKM,policy_EnvC_LMK, policy_EnvC_MKL, policy_EnvC_MLK]\n",
    "#desirePriors = [1/6,1/6,1/6,1/6,1/6,1/6]\n",
    "#desirePriors = [.160,.163,.166,.169,.172,.175]\n",
    "desirePriors = [.1666,.167,.1675,.168,.1685,.169]\n",
    "\n",
    "stateT1 = inferBelief(positionTrajectory1, world1)\n",
    "stateT2 = inferBelief(positionTrajectory2, world2)\n",
    "stateT3 = inferBelief(positionTrajectory3, world3)\n",
    "\n",
    "getPreferencePosterior1 = PerformDesireInference(beliefTransition_EnvC, preferencePolicies, desirePriors, stateT1)\n",
    "posterior1 = getPreferencePosterior1()\n",
    "\n",
    "getPreferencePosterior2 = PerformDesireInference(beliefTransition_EnvC, preferencePolicies, desirePriors, stateT2)\n",
    "posterior2 = getPreferencePosterior2()\n",
    "\n",
    "getPreferencePosterior3 = PerformDesireInference(beliefTransition_EnvC, preferencePolicies, desirePriors, stateT3)\n",
    "posterior3 = getPreferencePosterior3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T09:16:26.911260Z",
     "start_time": "2019-03-05T09:16:26.898796Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotPosteriors(posteriors, title=\"\", labels=['KLM', 'KML', 'LKM', 'LMK', 'MKL', 'MLK'], subplotRowNumber = 2, subplotColNumber = 3, figDim = (10,5)):\n",
    "    x, y  = posteriors.shape\n",
    "    fig, ax = plt.subplots(nrows=subplotRowNumber, ncols=subplotColNumber, figsize = figDim)\n",
    "    colors = plt.cm.viridis(np.linspace(0,1,y))\n",
    "    plotIndex = 0 \n",
    "    for row in ax:\n",
    "        for col in row:\n",
    "            col.plot(range(x), posteriors[:,plotIndex], color = colors[plotIndex], label = labels[plotIndex])\n",
    "            col.legend()\n",
    "            plotIndex += 1\n",
    "    fig.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T09:16:28.106604Z",
     "start_time": "2019-03-05T09:16:27.816594Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotPosteriors(posterior1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T01:35:14.587444Z",
     "start_time": "2019-03-05T01:35:14.310872Z"
    }
   },
   "outputs": [],
   "source": [
    "plotPosteriors(posterior2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T01:35:23.846867Z",
     "start_time": "2019-03-05T01:35:23.578891Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotPosteriors(posterior3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T01:10:20.175566Z",
     "start_time": "2019-03-05T01:10:20.165095Z"
    }
   },
   "outputs": [],
   "source": [
    "print(posterior3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
